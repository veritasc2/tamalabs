<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>What is Tama Doing? - Tama Labs</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@400;600&display=swap" rel="stylesheet">
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    html {
      scroll-behavior: smooth;
    }

    body {
      font-family: 'Inter', sans-serif;
      font-weight: 300;
      line-height: 1.8;
      color: #1a1a1a;
      background: #fefefe;
      font-size: 16px;
    }

    .container {
      max-width: 680px;
      margin: 0 auto;
      padding: 80px 40px;
    }

    /* Header for the article page */
    .article-header {
        text-align: center;
        margin-bottom: 80px;
    }

    h1 {
      font-size: clamp(2.5rem, 6vw, 3.5rem);
      font-weight: 200;
      letter-spacing: -0.03em;
      margin-bottom: 16px;
      color: #000;
    }
    
    .article-date {
        font-size: 0.85rem;
        color: #999;
        font-weight: 300;
    }

    /* Section headers */
    h2 {
      font-size: 1.5rem;
      font-weight: 300;
      margin-top: 64px;
      margin-bottom: 32px;
      text-align: left;
      color: #000;
      letter-spacing: -0.01em;
      border-bottom: 1px solid #f0f0f0;
      padding-bottom: 16px;
    }
    
    p {
        margin-bottom: 1.5em;
        color: #333;
    }
    
    strong {
        font-weight: 600;
        color: #000;
    }

    ul {
        list-style-position: inside;
        padding-left: 8px;
        margin-bottom: 1.5em;
    }
    
    li {
        margin-bottom: 1em;
        color: #333;
    }

    /* Back link */
    .back-link-container {
        margin-top: 80px;
        text-align: center;
    }
    
    .back-link {
      color: #000;
      text-decoration: none;
      font-weight: 400;
      font-size: 1rem;
      padding: 16px 32px;
      border: 1px solid #e0e0e0;
      display: inline-block;
      transition: all 0.3s ease;
      letter-spacing: 0.02em;
    }

    .back-link:hover {
      background: #000;
      color: #fff;
      border-color: #000;
    }

    /* Footer - Barely there */
    footer {
      margin-top: 160px;
      padding-top: 40px;
      border-top: 1px solid #f0f0f0;
      text-align: center;
      font-size: 0.8rem;
      color: #ccc;
      font-weight: 300;
    }

    footer a {
      color: #999;
      text-decoration: none;
      transition: color 0.3s ease;
    }

    footer a:hover {
      color: #666;
    }

    /* Mobile responsive */
    @media (max-width: 768px) {
      .container {
        padding: 60px 24px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header class="article-header">
      <h1>What is Tama Doing?</h1>
      <p class="article-date">Published on June 9, 2025</p>
    </header>

    <main>
      <article>
        <section id="context">
          <h2>Context</h2>
          <p>
            LLMs and Transformers aren’t the final word in machine intelligence. Their performance comes at an unsustainable energy cost. Training and running these models consumes megawatts — yet your brain, a supercomputer of remarkable efficiency, runs on just 20 watts (assuming you're a Homo sapiens reading this). Something doesn’t add up. It’s time to rethink the approach.
          </p>
        </section>

        <section id="vision">
          <h2>Vision</h2>
          <p>
            Taking inspiration from biological brains, we have developed a neural model that demonstrates the associative memory of humans by fusing <strong>Spiking Neural Networks</strong> and <strong>Knowledge Graph Networks</strong>. In parallel, we are integrating the spiking neural principles of biological brains and the dynamic control of <strong>State Space Models</strong> to create a foundational model capable of being in the drivers seat behind manual machinery. This means we are making a model that can run cloudless and on the power of a battery pack. These are characteristics that foundational models today from OpenAI, Google or Anthropic cannot access due to their architectures.
          </p>
          <p>
            Tama’s vision is to build intelligence that is shrewdly energy efficient and autonomous for our physical reality to support humanity in our endeavors:
          </p>
          <ul>
            <li>Imagine drone swarms capable of completing inspection of large renewable energy farms using verbal prompts.</li>
            <li>Or a swarm of airport ground support vehicles moving equipment, refueling planes and transporting luggage.</li>
            <li>Maintenance and inspection of underwater data cables.</li>
            <li>Bring entire last-century factories online and alive.</li>
            <li>Connecting a network of traffic lights to autonomously tune lights to reduce waiting times.</li>
            <li>Experience an autonomous swarm of vehicles that remove snow and salt the roads based on weather forecasts and road usage.</li>
            <li>Mapping settlements with autonomous life support agents before humans arrive.</li>
          </ul>
          <p>
            To enable this hardware AI-powered future, Tama will need to create a spiking neural network capable of perceiving and reasoning its environment around us. Our plan is to train baseline capabilities through virtual simulations before moving into the real world.
          </p>
        </section>

        <section id="product">
          <h2>Product and Monetization</h2>
          <p>
            We are using <strong>Spiking State Space Models</strong> to create <strong>retrofit autonomous kits (RAKs)</strong> to turn manual machinery not just autonomous but intelligent. This means that we are building a ‘nervous system’ that can augment any legacy machinery to be capable of making decisions, navigating its environment, performing its functions, and working as a swarm without connecting to the cloud. We are going to start with making low-level drones fully intelligent as a proof of concept to run inspections on planes and then move on to turning forklifts and airport ground support equipment to autonomous swarms.
          </p>
          <p>
            Tama will monetize by leasing the hardware and charging the use of the model by tokens. (We define tokens as a chain of thoughts or intensity of work the model is doing). We believe that this is the right approach because these machines represent large capital expenditures so ripping and replacing would require significant investments. We want to create autonomy within existing systems.
          </p>
        </section>
      </article>
      
      <div class="back-link-container">
          <a href="index.html" class="back-link">← Back to Home</a>
      </div>
    </main>

    <footer>
      <p>Follow us <a href="https://twitter.com/tama_ai" target="_blank" rel="noopener noreferrer">@tama_ai</a></p>
      <p>&copy; 2025 Tama Labs</p>
    </footer>
  </div>
</body>
</html>
